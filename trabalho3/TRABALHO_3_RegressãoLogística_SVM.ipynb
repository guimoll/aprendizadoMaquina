{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# PARTE 3 E 4: REGRESSÃO LOGÍSTICA E SVM"
   ],
   "metadata": {
    "id": "yRQiqgkhCpob"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ],
   "metadata": {
    "id": "LbqgTd_2W97_",
    "ExecuteTime": {
     "end_time": "2025-11-02T14:15:50.790560Z",
     "start_time": "2025-11-02T14:15:50.786559Z"
    }
   },
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PARTE 3: Regressão Logística"
   ],
   "metadata": {
    "id": "Da6UjkoKUiH8"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Utilize a base de dados construída no Trabalho 3 ‘risco_credito.pkl’, que possui 14 registros, para testar o algoritmo de Regressão Logística.\n",
    "\n",
    "2. Faça o Encoder dos dados e, para facilitar, como fizemos na aula teórica, apague os registros que possuem a classe ‘moderado’. No total teremos 11 registros.\n",
    "\n",
    "3. Treine o algoritmo de regressão logística e utilize o parâmetro ‘random_state =1’ para ter sempre o mesmo resultado.\n",
    "\n",
    "4. Utilize o comando ‘.intercept_’ para ter o resultado do B0.\n",
    "O resultado deve ser =-0.80828993\n",
    "\n",
    "5. Utilize o comando ‘.coef_’ para ter o resultado dos demais parâmetros que deve ser:\n",
    "array([[-0.76704533,  0.23906678, -0.47976059,  1.12186218]])\n",
    "\n",
    "6. Agora utilize o comando ‘predict’ para fazer o teste do seu algoritmo com:\n",
    "\n",
    "    a) história boa, dívida alta, garantias nenhuma, renda > 35\n",
    "    (o resultado desse teste deve ser ‘baixo’)\n",
    "\n",
    "    b) história ruim, dívida alta, garantias adequada, renda < 15\n",
    "    (o resultado desse teste deve ser ‘alto’)"
   ],
   "metadata": {
    "id": "VaFYpDAbC8tW"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aST3PJQ-URtX",
    "ExecuteTime": {
     "end_time": "2025-11-02T14:15:50.823979Z",
     "start_time": "2025-11-02T14:15:50.819763Z"
    }
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Carregar a base de dados risco_credito.pkl"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T14:15:50.846897Z",
     "start_time": "2025-11-02T14:15:50.836498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Carregar o dataset original para obter os labels\n",
    "dataset_risco_credito = pd.read_csv('dataset_risco_credito.csv')\n",
    "print(\"Dataset original:\")\n",
    "print(dataset_risco_credito)\n",
    "print(f\"\\nTotal de registros: {len(dataset_risco_credito)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset original:\n",
      "        historia divida garantias     renda     risco\n",
      "0           ruim   alta   nenhuma      0_15      alto\n",
      "1   desconhecida   alta   nenhuma     15_35      alto\n",
      "2   desconhecida  baixa   nenhuma     15_35  moderado\n",
      "3   desconhecida  baixa   nenhuma  acima_35      alto\n",
      "4   desconhecida  baixa   nenhuma  acima_35     baixo\n",
      "5   desconhecida  baixa  adequada  acima_35     baixo\n",
      "6           ruim  baixa   nenhuma      0_15      alto\n",
      "7           ruim  baixa  adequada  acima_35  moderado\n",
      "8            boa  baixa   nenhuma  acima_35     baixo\n",
      "9            boa   alta  adequada  acima_35     baixo\n",
      "10           boa   alta   nenhuma      0_15      alto\n",
      "11           boa   alta   nenhuma     15_35  moderado\n",
      "12           boa   alta   nenhuma  acima_35     baixo\n",
      "13          ruim   alta   nenhuma     15_35      alto\n",
      "\n",
      "Total de registros: 14\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Remover registros com classe 'moderado' e fazer o encoding"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T14:15:50.878356Z",
     "start_time": "2025-11-02T14:15:50.866916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Filtrar dados removendo a classe 'moderado'\n",
    "dataset_filtrado = dataset_risco_credito[dataset_risco_credito['risco'] != 'moderado'].copy()\n",
    "print(f\"\\nDataset após remover 'moderado':\")\n",
    "print(dataset_filtrado)\n",
    "print(f\"\\nTotal de registros: {len(dataset_filtrado)}\")\n",
    "\n",
    "# Separar X e y\n",
    "X_risco_credito_filtrado = dataset_filtrado.iloc[:, 0:-1].values\n",
    "y_risco_credito_filtrado = dataset_filtrado.iloc[:, -1].values\n",
    "\n",
    "# Fazer encoding das features (X)\n",
    "X_encoded = X_risco_credito_filtrado.copy()\n",
    "label_encoders = []\n",
    "\n",
    "for i in range(X_encoded.shape[1]):\n",
    "    le = LabelEncoder()\n",
    "    X_encoded[:, i] = le.fit_transform(X_encoded[:, i])\n",
    "    label_encoders.append(le)\n",
    "\n",
    "# Fazer encoding da classe (y)\n",
    "le_y = LabelEncoder()\n",
    "y_encoded = le_y.fit_transform(y_risco_credito_filtrado)\n",
    "\n",
    "print(\"\\nX codificado:\")\n",
    "print(X_encoded)\n",
    "print(\"\\ny codificado:\")\n",
    "print(y_encoded)\n",
    "print(f\"\\nClasses: {le_y.classes_}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset após remover 'moderado':\n",
      "        historia divida garantias     renda  risco\n",
      "0           ruim   alta   nenhuma      0_15   alto\n",
      "1   desconhecida   alta   nenhuma     15_35   alto\n",
      "3   desconhecida  baixa   nenhuma  acima_35   alto\n",
      "4   desconhecida  baixa   nenhuma  acima_35  baixo\n",
      "5   desconhecida  baixa  adequada  acima_35  baixo\n",
      "6           ruim  baixa   nenhuma      0_15   alto\n",
      "8            boa  baixa   nenhuma  acima_35  baixo\n",
      "9            boa   alta  adequada  acima_35  baixo\n",
      "10           boa   alta   nenhuma      0_15   alto\n",
      "12           boa   alta   nenhuma  acima_35  baixo\n",
      "13          ruim   alta   nenhuma     15_35   alto\n",
      "\n",
      "Total de registros: 11\n",
      "\n",
      "X codificado:\n",
      "[[2 0 1 0]\n",
      " [1 0 1 1]\n",
      " [1 1 1 2]\n",
      " [1 1 1 2]\n",
      " [1 1 0 2]\n",
      " [2 1 1 0]\n",
      " [0 1 1 2]\n",
      " [0 0 0 2]\n",
      " [0 0 1 0]\n",
      " [0 0 1 2]\n",
      " [2 0 1 1]]\n",
      "\n",
      "y codificado:\n",
      "[0 0 0 1 1 0 1 1 0 1 0]\n",
      "\n",
      "Classes: ['alto' 'baixo']\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Treinar o algoritmo de Regressão Logística"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T14:15:50.904870Z",
     "start_time": "2025-11-02T14:15:50.895364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Treinar o modelo de regressão logística\n",
    "reglog_risco_credito = LogisticRegression(random_state=1)\n",
    "reglog_risco_credito.fit(X_encoded, y_encoded)\n",
    "\n",
    "print(\"Modelo de Regressão Logística treinado com sucesso!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo de Regressão Logística treinado com sucesso!\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Verificar o intercepto (B0)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T14:15:50.920134Z",
     "start_time": "2025-11-02T14:15:50.916882Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Intercepto (B0): {reglog_risco_credito.intercept_[0]}\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercepto (B0): -0.8085515186482205\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Verificar os coeficientes"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T14:15:50.939834Z",
     "start_time": "2025-11-02T14:15:50.936656Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Coeficientes: {reglog_risco_credito.coef_}\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficientes: [[-0.76706797  0.23921064 -0.47989768  1.12196145]]\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. Fazer predições com os exemplos"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T14:15:50.966778Z",
     "start_time": "2025-11-02T14:15:50.958842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Exemplo a) história boa, dívida alta, garantias nenhuma, renda > 35\n",
    "exemplo_a = [\n",
    "    label_encoders[0].transform(['boa'])[0],\n",
    "    label_encoders[1].transform(['alta'])[0],\n",
    "    label_encoders[2].transform(['nenhuma'])[0],\n",
    "    label_encoders[3].transform(['acima_35'])[0]\n",
    "]\n",
    "\n",
    "# Exemplo b) história ruim, dívida alta, garantias adequada, renda < 15\n",
    "exemplo_b = [\n",
    "    label_encoders[0].transform(['ruim'])[0],\n",
    "    label_encoders[1].transform(['alta'])[0],\n",
    "    label_encoders[2].transform(['adequada'])[0],\n",
    "    label_encoders[3].transform(['0_15'])[0]\n",
    "]\n",
    "\n",
    "# Fazer predições\n",
    "pred_a = reglog_risco_credito.predict([exemplo_a])[0]\n",
    "pred_b = reglog_risco_credito.predict([exemplo_b])[0]\n",
    "\n",
    "# Converter para labels originais\n",
    "classe_a = le_y.inverse_transform([pred_a])[0]\n",
    "classe_b = le_y.inverse_transform([pred_b])[0]\n",
    "\n",
    "print(f\"\\nPredição exemplo a) história boa, dívida alta, garantias nenhuma, renda > 35: {classe_a}\")\n",
    "print(f\"Predição exemplo b) história ruim, dívida alta, garantias adequada, renda < 15: {classe_b}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predição exemplo a) história boa, dívida alta, garantias nenhuma, renda > 35: baixo\n",
      "Predição exemplo b) história ruim, dívida alta, garantias adequada, renda < 15: alto\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Algoritmo de Regressão Logística para uma base de dados maior (Credit Data)"
   ],
   "metadata": {
    "id": "HIMAinxLEYMi"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "7. Agora aplique a Regressão Logística na base de dados ‘credit1.pkl’. De quanto foi a taxa de acerto?\n",
    "\n",
    "8. O resultado com a base de dados ‘credit1.pkl’ é melhor que os resultados do Naive Bayes e das Florestas Aleatórias? Descreva sua análise de resultados (observe que para isso você deverá visualizar os resultados da Matriz de Confusão, acurácia, precisão e recall)."
   ],
   "metadata": {
    "id": "PKDgYLDdqAsv"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T14:15:51.016811Z",
     "start_time": "2025-11-02T14:15:50.986785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "# carregar dados\n",
    "with open('credit1.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# espera-se que o pickle contenha: X_train, y_train, X_test, y_test\n",
    "if isinstance(data, (list, tuple)) and len(data) == 4:\n",
    "    X_train, y_train, X_test, y_test = data\n",
    "else:\n",
    "    raise ValueError('arquivo invalido')\n",
    "\n",
    "# garantir numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print('Shapes:')\n",
    "print('X_train.shape:', X_train.shape)\n",
    "print('y_train.shape:', y_train.shape)\n",
    "print('X_test.shape:', X_test.shape)\n",
    "print('y_test.shape:', y_test.shape)\n",
    "\n",
    "# Treinar Regressão Logística\n",
    "logreg = LogisticRegression(random_state=1, solver='lbfgs', max_iter=2000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predição\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Métricas\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "rec = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('\\nRESULTADOS DA REGRESSÃO LOGÍSTICA')\n",
    "print('Acurácia:', acc)\n",
    "print('Precisão (macro):', prec)\n",
    "print('Revocação (macro):', rec)\n",
    "print('\\nMatriz de Confusão:\\n', cm)\n",
    "print('\\nRelatório de Classificação:\\n', classification_report(y_test, y_pred, zero_division=0))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "X_train.shape: (1500, 3)\n",
      "y_train.shape: (1500,)\n",
      "X_test.shape: (500, 3)\n",
      "y_test.shape: (500,)\n",
      "\n",
      "RESULTADOS DA REGRESSÃO LOGÍSTICA\n",
      "Acurácia: 0.946\n",
      "Precisão (macro): 0.8808070901892412\n",
      "Revocação (macro): 0.8757167431192661\n",
      "\n",
      "Matriz de Confusão:\n",
      " [[423  13]\n",
      " [ 14  50]]\n",
      "\n",
      "Relatório de Classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       436\n",
      "           1       0.79      0.78      0.79        64\n",
      "\n",
      "    accuracy                           0.95       500\n",
      "   macro avg       0.88      0.88      0.88       500\n",
      "weighted avg       0.95      0.95      0.95       500\n",
      "\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "source": [
    "Não, a Regressão Logística não é melhor que o Naive Bayes nem que a Floresta Aleatória (Logistic acc 0.946 vs NB 0.982 e RF 0.97).\n",
    "O Naive Bayes lidera (acc 0.982, recall classe1 0.95), RF é 2º (acc 0.97, recall 0.81) e Logistic tem recall bem menor para a classe minoritária (0.78), logo perde muitos positivos.\n",
    "\n",
    "#PARTE 4: SVM"
   ],
   "metadata": {
    "id": "6IUqVdYzbXOi"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Aplique o algoritmo SVM na base de dados ‘credit.pkl’.\n",
    "2. Inicialmente treine o SVM com kernel linear, valor do parâmetro C = 1.0 e ‘random_state =1’\n",
    "3. Utilize o comando do sklearn accuray_score para calcular a acurácia do seu algoritmo. O resultado deve ser 0.946\n",
    "4. Teste os demais kernels e anote os resultados. Qual o melhor kernel para a sua base de dados?\n",
    "    * Polinomial\n",
    "    * Sigmoide\n",
    "    * rbf\n",
    "5. Aumente o valor do parâmetro C aplicado ao melhor kernel e verifique se há mudanças no resultado do seu SVM.\n",
    "6. O Grid Search (pesquisa em grade) é uma técnica utilizada para melhorar a precisão e a generalização dos modelos de aprendizado de máquina. Ela é usada para realizar ajustes de hiperparâmetros durante o treinamento de um modelo. O grid search automatiza o processo de encontrar hiperparâmetros ideais, economizando esforço humano em comparação com o ajuste manual, mas pode até ser mais custoso do ponto de vista de desempenho, pois testa todas as combinações possíveis e retorna a que obteve melhor desempenho.\n",
    "Agora, aplique o GridSearch do Scikit-Learn (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) para ajudar a identificar os melhores hiperparâmetros para o seu modelo. Qual foi a melhor combinação de hiperparâmetros encontrada? O modelo com melhor desempenho foi obtido com os parâmetros ajustados manualmente ou com o GridSearch?"
   ],
   "metadata": {
    "id": "cinByF1FEmk_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVC"
   ],
   "metadata": {
    "id": "Li6Land0bcmM",
    "ExecuteTime": {
     "end_time": "2025-11-02T14:15:51.041907Z",
     "start_time": "2025-11-02T14:15:51.037909Z"
    }
   },
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Base de Dados Credit Data"
   ],
   "metadata": {
    "id": "EmeKgstpc2Tt"
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "oLxq123_r5n_"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Análise dos resultados dos 4 algoritmos utilizados:"
   ],
   "metadata": {
    "id": "K_gHfT6fqXeI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "6. O resultado do SVM é melhor que os resultados do Naive Bayes, Florestas Aleatórias e Regressão Logística? Descreva sua análise de resultados (observe que para isso você deverá visualizar os resultados da Matriz de Confusão, acurácia, precisão e recall)."
   ],
   "metadata": {
    "id": "7DrS--HFqfjq"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T14:15:51.059003Z",
     "start_time": "2025-11-02T14:15:51.056001Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Conclusão\n",
    "# Descreva aqui suas conclusões sobre os resultados obtidos com os diferentes algoritmos e a importância da escolha adequada do modelo e hiperparâmetros.\n"
   ]
  }
 ]
}
