{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# PARTE 3 E 4: REGRESSÃO LOGÍSTICA E SVM"
   ],
   "metadata": {
    "id": "yRQiqgkhCpob"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ],
   "metadata": {
    "id": "LbqgTd_2W97_",
    "ExecuteTime": {
     "end_time": "2025-11-02T21:33:53.399544Z",
     "start_time": "2025-11-02T21:33:53.395721Z"
    }
   },
   "outputs": [],
   "execution_count": 94
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PARTE 3: Regressão Logística"
   ],
   "metadata": {
    "id": "Da6UjkoKUiH8"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Utilize a base de dados construída no Trabalho 3 ‘risco_credito.pkl’, que possui 14 registros, para testar o algoritmo de Regressão Logística.\n",
    "\n",
    "2. Faça o Encoder dos dados e, para facilitar, como fizemos na aula teórica, apague os registros que possuem a classe ‘moderado’. No total teremos 11 registros.\n",
    "\n",
    "3. Treine o algoritmo de regressão logística e utilize o parâmetro ‘random_state =1’ para ter sempre o mesmo resultado.\n",
    "\n",
    "4. Utilize o comando ‘.intercept_’ para ter o resultado do B0.\n",
    "O resultado deve ser =-0.80828993\n",
    "\n",
    "5. Utilize o comando ‘.coef_’ para ter o resultado dos demais parâmetros que deve ser:\n",
    "array([[-0.76704533,  0.23906678, -0.47976059,  1.12186218]])\n",
    "\n",
    "6. Agora utilize o comando ‘predict’ para fazer o teste do seu algoritmo com:\n",
    "\n",
    "    a) história boa, dívida alta, garantias nenhuma, renda > 35\n",
    "    (o resultado desse teste deve ser ‘baixo’)\n",
    "\n",
    "    b) história ruim, dívida alta, garantias adequada, renda < 15\n",
    "    (o resultado desse teste deve ser ‘alto’)"
   ],
   "metadata": {
    "id": "VaFYpDAbC8tW"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aST3PJQ-URtX",
    "ExecuteTime": {
     "end_time": "2025-11-02T21:33:53.418955Z",
     "start_time": "2025-11-02T21:33:53.414604Z"
    }
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle"
   ],
   "outputs": [],
   "execution_count": 95
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Carregar a base de dados risco_credito.pkl"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T21:33:53.443991Z",
     "start_time": "2025-11-02T21:33:53.429484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_risco_credito = pd.read_csv('dataset_risco_credito.csv')\n",
    "print(\"Dataset original:\")\n",
    "print(dataset_risco_credito)\n",
    "print(f\"\\nTotal de registros: {len(dataset_risco_credito)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset original:\n",
      "        historia divida garantias     renda     risco\n",
      "0           ruim   alta   nenhuma      0_15      alto\n",
      "1   desconhecida   alta   nenhuma     15_35      alto\n",
      "2   desconhecida  baixa   nenhuma     15_35  moderado\n",
      "3   desconhecida  baixa   nenhuma  acima_35      alto\n",
      "4   desconhecida  baixa   nenhuma  acima_35     baixo\n",
      "5   desconhecida  baixa  adequada  acima_35     baixo\n",
      "6           ruim  baixa   nenhuma      0_15      alto\n",
      "7           ruim  baixa  adequada  acima_35  moderado\n",
      "8            boa  baixa   nenhuma  acima_35     baixo\n",
      "9            boa   alta  adequada  acima_35     baixo\n",
      "10           boa   alta   nenhuma      0_15      alto\n",
      "11           boa   alta   nenhuma     15_35  moderado\n",
      "12           boa   alta   nenhuma  acima_35     baixo\n",
      "13          ruim   alta   nenhuma     15_35      alto\n",
      "\n",
      "Total de registros: 14\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Remover registros com classe 'moderado' e fazer o encoding"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T21:33:53.468359Z",
     "start_time": "2025-11-02T21:33:53.454515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_filtrado = dataset_risco_credito[dataset_risco_credito['risco'] != 'moderado'].copy()\n",
    "print(f\"\\nDataset após remover 'moderado':\")\n",
    "print(dataset_filtrado)\n",
    "print(f\"\\nTotal de registros: {len(dataset_filtrado)}\")\n",
    "\n",
    "X_risco_credito_filtrado = dataset_filtrado.iloc[:, 0:-1].values\n",
    "y_risco_credito_filtrado = dataset_filtrado.iloc[:, -1].values\n",
    "\n",
    "X_encoded = X_risco_credito_filtrado.copy()\n",
    "label_encoders = []\n",
    "\n",
    "for i in range(X_encoded.shape[1]):\n",
    "    le = LabelEncoder()\n",
    "    X_encoded[:, i] = le.fit_transform(X_encoded[:, i])\n",
    "    label_encoders.append(le)\n",
    "\n",
    "le_y = LabelEncoder()\n",
    "y_encoded = le_y.fit_transform(y_risco_credito_filtrado)\n",
    "\n",
    "print(\"\\nX codificado:\")\n",
    "print(X_encoded)\n",
    "print(\"\\ny codificado:\")\n",
    "print(y_encoded)\n",
    "print(f\"\\nClasses: {le_y.classes_}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset após remover 'moderado':\n",
      "        historia divida garantias     renda  risco\n",
      "0           ruim   alta   nenhuma      0_15   alto\n",
      "1   desconhecida   alta   nenhuma     15_35   alto\n",
      "3   desconhecida  baixa   nenhuma  acima_35   alto\n",
      "4   desconhecida  baixa   nenhuma  acima_35  baixo\n",
      "5   desconhecida  baixa  adequada  acima_35  baixo\n",
      "6           ruim  baixa   nenhuma      0_15   alto\n",
      "8            boa  baixa   nenhuma  acima_35  baixo\n",
      "9            boa   alta  adequada  acima_35  baixo\n",
      "10           boa   alta   nenhuma      0_15   alto\n",
      "12           boa   alta   nenhuma  acima_35  baixo\n",
      "13          ruim   alta   nenhuma     15_35   alto\n",
      "\n",
      "Total de registros: 11\n",
      "\n",
      "X codificado:\n",
      "[[2 0 1 0]\n",
      " [1 0 1 1]\n",
      " [1 1 1 2]\n",
      " [1 1 1 2]\n",
      " [1 1 0 2]\n",
      " [2 1 1 0]\n",
      " [0 1 1 2]\n",
      " [0 0 0 2]\n",
      " [0 0 1 0]\n",
      " [0 0 1 2]\n",
      " [2 0 1 1]]\n",
      "\n",
      "y codificado:\n",
      "[0 0 0 1 1 0 1 1 0 1 0]\n",
      "\n",
      "Classes: ['alto' 'baixo']\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Treinar o algoritmo de Regressão Logística"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T21:33:53.496926Z",
     "start_time": "2025-11-02T21:33:53.478882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reglog_risco_credito = LogisticRegression(random_state=1)\n",
    "reglog_risco_credito.fit(X_encoded, y_encoded)\n",
    "\n",
    "print(\"Modelo de Regressão Logística treinado com sucesso!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo de Regressão Logística treinado com sucesso!\n"
     ]
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Verificar o intercepto (B0)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T21:33:53.528390Z",
     "start_time": "2025-11-02T21:33:53.524507Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Intercepto (B0): {reglog_risco_credito.intercept_[0]}\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercepto (B0): -0.8085515186482205\n"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Verificar os coeficientes"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T21:33:53.550255Z",
     "start_time": "2025-11-02T21:33:53.546191Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Coeficientes: {reglog_risco_credito.coef_}\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficientes: [[-0.76706797  0.23921064 -0.47989768  1.12196145]]\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. Fazer predições com os exemplos"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T21:33:53.575722Z",
     "start_time": "2025-11-02T21:33:53.567039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Exemplo a) história boa, dívida alta, garantias nenhuma, renda > 35\n",
    "exemplo_a = [\n",
    "    label_encoders[0].transform(['boa'])[0],\n",
    "    label_encoders[1].transform(['alta'])[0],\n",
    "    label_encoders[2].transform(['nenhuma'])[0],\n",
    "    label_encoders[3].transform(['acima_35'])[0]\n",
    "]\n",
    "\n",
    "# Exemplo b) história ruim, dívida alta, garantias adequada, renda < 15\n",
    "exemplo_b = [\n",
    "    label_encoders[0].transform(['ruim'])[0],\n",
    "    label_encoders[1].transform(['alta'])[0],\n",
    "    label_encoders[2].transform(['adequada'])[0],\n",
    "    label_encoders[3].transform(['0_15'])[0]\n",
    "]\n",
    "\n",
    "pred_a = reglog_risco_credito.predict([exemplo_a])[0]\n",
    "pred_b = reglog_risco_credito.predict([exemplo_b])[0]\n",
    "\n",
    "classe_a = le_y.inverse_transform([pred_a])[0]\n",
    "classe_b = le_y.inverse_transform([pred_b])[0]\n",
    "\n",
    "print(f\"\\nPredição exemplo a) história boa, dívida alta, garantias nenhuma, renda > 35: {classe_a}\")\n",
    "print(f\"Predição exemplo b) história ruim, dívida alta, garantias adequada, renda < 15: {classe_b}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predição exemplo a) história boa, dívida alta, garantias nenhuma, renda > 35: baixo\n",
      "Predição exemplo b) história ruim, dívida alta, garantias adequada, renda < 15: alto\n"
     ]
    }
   ],
   "execution_count": 101
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Algoritmo de Regressão Logística para uma base de dados maior (Credit Data)"
   ],
   "metadata": {
    "id": "HIMAinxLEYMi"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "7. Agora aplique a Regressão Logística na base de dados ‘credit1.pkl’. De quanto foi a taxa de acerto?\n",
    "\n",
    "8. O resultado com a base de dados ‘credit1.pkl’ é melhor que os resultados do Naive Bayes e das Florestas Aleatórias? Descreva sua análise de resultados (observe que para isso você deverá visualizar os resultados da Matriz de Confusão, acurácia, precisão e recall)."
   ],
   "metadata": {
    "id": "PKDgYLDdqAsv"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T21:33:53.621343Z",
     "start_time": "2025-11-02T21:33:53.595765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "with open('credit1.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "if isinstance(data, (list, tuple)) and len(data) == 4:\n",
    "    X_train, y_train, X_test, y_test = data\n",
    "else:\n",
    "    raise ValueError('arquivo invalido')\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print('Shapes:')\n",
    "print('X_train.shape:', X_train.shape)\n",
    "print('y_train.shape:', y_train.shape)\n",
    "print('X_test.shape:', X_test.shape)\n",
    "print('y_test.shape:', y_test.shape)\n",
    "\n",
    "logreg = LogisticRegression(random_state=1, solver='lbfgs', max_iter=2000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "rec = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('\\nRESULTADOS DA REGRESSÃO LOGÍSTICA')\n",
    "print('Acurácia:', acc)\n",
    "print('Precisão (macro):', prec)\n",
    "print('Revocação (macro):', rec)\n",
    "print('\\nMatriz de Confusão:\\n', cm)\n",
    "print('\\nRelatório de Classificação:\\n', classification_report(y_test, y_pred, zero_division=0))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "X_train.shape: (1500, 3)\n",
      "y_train.shape: (1500,)\n",
      "X_test.shape: (500, 3)\n",
      "y_test.shape: (500,)\n",
      "\n",
      "RESULTADOS DA REGRESSÃO LOGÍSTICA\n",
      "Acurácia: 0.946\n",
      "Precisão (macro): 0.8808070901892412\n",
      "Revocação (macro): 0.8757167431192661\n",
      "\n",
      "Matriz de Confusão:\n",
      " [[423  13]\n",
      " [ 14  50]]\n",
      "\n",
      "Relatório de Classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       436\n",
      "           1       0.79      0.78      0.79        64\n",
      "\n",
      "    accuracy                           0.95       500\n",
      "   macro avg       0.88      0.88      0.88       500\n",
      "weighted avg       0.95      0.95      0.95       500\n",
      "\n"
     ]
    }
   ],
   "execution_count": 102
  },
  {
   "cell_type": "markdown",
   "source": [
    "Não, a Regressão Logística não é melhor que o Naive Bayes nem que a Floresta Aleatória (Logistic acc 0.946 vs NB 0.982 e RF 0.97).\n",
    "O Naive Bayes lidera (acc 0.982, recall classe1 0.95), RF é 2º (acc 0.97, recall 0.81) e Logistic tem recall bem menor para a classe minoritária (0.78), logo perde muitos positivos.\n",
    "\n",
    "#PARTE 4: SVM"
   ],
   "metadata": {
    "id": "6IUqVdYzbXOi"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Aplique o algoritmo SVM na base de dados ‘credit.pkl’.\n",
    "2. Inicialmente treine o SVM com kernel linear, valor do parâmetro C = 1.0 e ‘random_state =1’\n",
    "3. Utilize o comando do sklearn accuray_score para calcular a acurácia do seu algoritmo. O resultado deve ser 0.946\n",
    "4. Teste os demais kernels e anote os resultados. Qual o melhor kernel para a sua base de dados?\n",
    "    * Polinomial\n",
    "    * Sigmoide\n",
    "    * rbf\n",
    "5. Aumente o valor do parâmetro C aplicado ao melhor kernel e verifique se há mudanças no resultado do seu SVM.\n",
    "6. O Grid Search (pesquisa em grade) é uma técnica utilizada para melhorar a precisão e a generalização dos modelos de aprendizado de máquina. Ela é usada para realizar ajustes de hiperparâmetros durante o treinamento de um modelo. O grid search automatiza o processo de encontrar hiperparâmetros ideais, economizando esforço humano em comparação com o ajuste manual, mas pode até ser mais custoso do ponto de vista de desempenho, pois testa todas as combinações possíveis e retorna a que obteve melhor desempenho.\n",
    "Agora, aplique o GridSearch do Scikit-Learn (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) para ajudar a identificar os melhores hiperparâmetros para o seu modelo. Qual foi a melhor combinação de hiperparâmetros encontrada? O modelo com melhor desempenho foi obtido com os parâmetros ajustados manualmente ou com o GridSearch?"
   ],
   "metadata": {
    "id": "cinByF1FEmk_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVC"
   ],
   "metadata": {
    "id": "Li6Land0bcmM",
    "ExecuteTime": {
     "end_time": "2025-11-02T21:33:53.632899Z",
     "start_time": "2025-11-02T21:33:53.628896Z"
    }
   },
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T21:33:53.736172Z",
     "start_time": "2025-11-02T21:33:53.646427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "with open('credit1.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "if isinstance(data, (list, tuple)) and len(data) == 4:\n",
    "    X_train, y_train, X_test, y_test = data\n",
    "else:\n",
    "    raise ValueError('erro na leitura do arquivo')\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "results_svm = {}\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('1. SVM com kernel LINEAR')\n",
    "print('='*60)\n",
    "svc_linear = SVC(kernel='linear', C=1.0, random_state=1)\n",
    "svc_linear.fit(X_train, y_train)\n",
    "y_pred_lin = svc_linear.predict(X_test)\n",
    "acc_lin = accuracy_score(y_test, y_pred_lin)\n",
    "print(f'Acurácia: {acc_lin}')\n",
    "print('Matriz de Confusão:\\n', confusion_matrix(y_test, y_pred_lin))\n",
    "print('\\nRelatório de Classificação:\\n', classification_report(y_test, y_pred_lin, zero_division=0))\n",
    "results_svm['linear'] = acc_lin\n",
    "\n",
    "# 2) Testar kernel POLINOMIAL\n",
    "print('\\n' + '='*60)\n",
    "print('2. SVM com kernel POLINOMIAL')\n",
    "print('='*60)\n",
    "svc_poly = SVC(kernel='poly', C=1.0, random_state=1)\n",
    "svc_poly.fit(X_train, y_train)\n",
    "y_pred_poly = svc_poly.predict(X_test)\n",
    "acc_poly = accuracy_score(y_test, y_pred_poly)\n",
    "print(f'Acurácia: {acc_poly}')\n",
    "print('Matriz de Confusão:\\n', confusion_matrix(y_test, y_pred_poly))\n",
    "print('\\nRelatório de Classificação:\\n', classification_report(y_test, y_pred_poly, zero_division=0))\n",
    "results_svm['poly'] = acc_poly\n",
    "\n",
    "# 3) Testar kernel SIGMOIDE\n",
    "print('\\n' + '='*60)\n",
    "print('3. SVM com kernel SIGMOIDE')\n",
    "print('='*60)\n",
    "svc_sigmoid = SVC(kernel='sigmoid', C=1.0, random_state=1)\n",
    "svc_sigmoid.fit(X_train, y_train)\n",
    "y_pred_sigmoid = svc_sigmoid.predict(X_test)\n",
    "acc_sigmoid = accuracy_score(y_test, y_pred_sigmoid)\n",
    "print(f'Acurácia: {acc_sigmoid}')\n",
    "print('Matriz de Confusão:\\n', confusion_matrix(y_test, y_pred_sigmoid))\n",
    "print('\\nRelatório de Classificação:\\n', classification_report(y_test, y_pred_sigmoid, zero_division=0))\n",
    "results_svm['sigmoid'] = acc_sigmoid\n",
    "\n",
    "# 4) Testar kernel RBF\n",
    "print('\\n' + '='*60)\n",
    "print('4. SVM com kernel RBF')\n",
    "print('='*60)\n",
    "svc_rbf = SVC(kernel='rbf', C=1.0, random_state=1)\n",
    "svc_rbf.fit(X_train, y_train)\n",
    "y_pred_rbf = svc_rbf.predict(X_test)\n",
    "acc_rbf = accuracy_score(y_test, y_pred_rbf)\n",
    "print(f'Acurácia: {acc_rbf}')\n",
    "print('Matriz de Confusão:\\n', confusion_matrix(y_test, y_pred_rbf))\n",
    "print('\\nRelatório de Classificação:\\n', classification_report(y_test, y_pred_rbf, zero_division=0))\n",
    "results_svm['rbf'] = acc_rbf\n",
    "\n",
    "# Comparação e identificação do melhor kernel\n",
    "print('\\n' + '='*60)\n",
    "print('COMPARAÇÃO DE KERNELS')\n",
    "print('='*60)\n",
    "for kernel, acc in results_svm.items():\n",
    "    print(f'{kernel:12s}: {acc:.4f}')\n",
    "\n",
    "best_kernel = max(results_svm.items(), key=lambda kv: kv[1])\n",
    "print(f'\\nMelhor kernel: {best_kernel[0]} com acurácia = {best_kernel[1]:.4f}')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "1. SVM com kernel LINEAR\n",
      "============================================================\n",
      "Acurácia: 0.946\n",
      "Matriz de Confusão:\n",
      " [[422  14]\n",
      " [ 13  51]]\n",
      "\n",
      "Relatório de Classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       436\n",
      "           1       0.78      0.80      0.79        64\n",
      "\n",
      "    accuracy                           0.95       500\n",
      "   macro avg       0.88      0.88      0.88       500\n",
      "weighted avg       0.95      0.95      0.95       500\n",
      "\n",
      "\n",
      "============================================================\n",
      "2. SVM com kernel POLINOMIAL\n",
      "============================================================\n",
      "Acurácia: 0.968\n",
      "Matriz de Confusão:\n",
      " [[433   3]\n",
      " [ 13  51]]\n",
      "\n",
      "Relatório de Classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       436\n",
      "           1       0.94      0.80      0.86        64\n",
      "\n",
      "    accuracy                           0.97       500\n",
      "   macro avg       0.96      0.89      0.92       500\n",
      "weighted avg       0.97      0.97      0.97       500\n",
      "\n",
      "\n",
      "============================================================\n",
      "3. SVM com kernel SIGMOIDE\n",
      "============================================================\n",
      "Acurácia: 0.838\n",
      "Matriz de Confusão:\n",
      " [[393  43]\n",
      " [ 38  26]]\n",
      "\n",
      "Relatório de Classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91       436\n",
      "           1       0.38      0.41      0.39        64\n",
      "\n",
      "    accuracy                           0.84       500\n",
      "   macro avg       0.64      0.65      0.65       500\n",
      "weighted avg       0.84      0.84      0.84       500\n",
      "\n",
      "\n",
      "============================================================\n",
      "4. SVM com kernel RBF\n",
      "============================================================\n",
      "Acurácia: 0.982\n",
      "Matriz de Confusão:\n",
      " [[434   2]\n",
      " [  7  57]]\n",
      "\n",
      "Relatório de Classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       436\n",
      "           1       0.97      0.89      0.93        64\n",
      "\n",
      "    accuracy                           0.98       500\n",
      "   macro avg       0.98      0.94      0.96       500\n",
      "weighted avg       0.98      0.98      0.98       500\n",
      "\n",
      "\n",
      "============================================================\n",
      "COMPARAÇÃO DE KERNELS\n",
      "============================================================\n",
      "linear      : 0.9460\n",
      "poly        : 0.9680\n",
      "sigmoid     : 0.8380\n",
      "rbf         : 0.9820\n",
      "\n",
      "Melhor kernel: rbf com acurácia = 0.9820\n",
      "\n",
      "Resultados salvos em credit1_svm_results.pkl\n"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Aumentando o C do kernel RBF para 2, teve um leve aumento na acuracia, totalizando 0.988. aumentando para 5, o resultado vai para 0.986, indicando que tem um limite máximo para melhoria do valor C\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Análise dos resultados dos 4 algoritmos utilizados:"
   ],
   "metadata": {
    "id": "K_gHfT6fqXeI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "6. O resultado do SVM é melhor que os resultados do Naive Bayes, Florestas Aleatórias e Regressão Logística? Descreva sua análise de resultados (observe que para isso você deverá visualizar os resultados da Matriz de Confusão, acurácia, precisão e recall).\n",
    "O SVM com RBF apresentou maior acurácia (0.982) e melhores métricas globais.\n",
    "\n",
    "A matriz mostra quase nenhum falso positivo/negativo e um recall alto para a classe 0 e aceitável para a classe 1.\n",
    "Comparando com NB, RF e LR, o SVM generalizou melhor e manteve maior equilíbrio entre precisão e recall."
   ],
   "metadata": {
    "id": "7DrS--HFqfjq"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T21:33:59.651340Z",
     "start_time": "2025-11-02T21:33:53.743345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle, numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "with open('credit1.pkl', 'rb') as f:\n",
    "    X_train, y_train, X_test, y_test = pickle.load(f)\n",
    "\n",
    "X_train, X_test = np.asarray(X_train), np.asarray(X_test)\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.3, 1, 3, 10, 30, 100],\n",
    "    'gamma': ['scale', 'auto', 0.1, 0.03, 0.01, 0.003, 0.001],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1_macro': 'f1_macro',\n",
    "    'recall_macro': 'recall_macro',\n",
    "    'precision_macro': 'precision_macro'\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    SVC(class_weight=None), # possivel ajustar o peso\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,\n",
    "    refit='f1_macro',\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"===== MELHOR COMBINAÇÃO (CV pelo f1_macro) =====\")\n",
    "print(grid.best_params_)\n",
    "print(f\"Melhor f1_macro (CV): {grid.best_score_:.4f}\")\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm  = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\n===== DESEMPENHO NO TESTE =====\")\n",
    "print(f\"Acurácia (teste): {acc:.3f}\")\n",
    "print(\"Matriz de Confusão (teste):\\n\", cm)\n",
    "print(\"\\nRelatório de Classificação (teste):\")\n",
    "print(classification_report(y_test, y_pred, digits=3))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== MELHOR COMBINAÇÃO (CV pelo f1_macro) =====\n",
      "{'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Melhor f1_macro (CV): 0.9839\n",
      "\n",
      "===== DESEMPENHO NO TESTE =====\n",
      "Acurácia (teste): 0.990\n",
      "Matriz de Confusão (teste):\n",
      " [[435   1]\n",
      " [  4  60]]\n",
      "\n",
      "Relatório de Classificação (teste):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.998     0.994       436\n",
      "           1      0.984     0.938     0.960        64\n",
      "\n",
      "    accuracy                          0.990       500\n",
      "   macro avg      0.987     0.968     0.977       500\n",
      "weighted avg      0.990     0.990     0.990       500\n",
      "\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Conclusão\n",
    "# Descreva aqui suas conclusões sobre os resultados obtidos com os diferentes algoritmos e a importância da escolha adequada do modelo e hiperparâmetros.\n",
    "Os resultados mostraram que modelos diferentes apresentam desempenhos distintos, mesmo usando a mesma base.\n",
    "Entre os algoritmos testados, o SVM com kernel RBF foi o que obteve o melhor desempenho geral.\n",
    "Além disso, o GridSearch ainda conseguiu melhorar esse SVM, aumentando acurácia e F1, principalmente para a classe minoritária.\n",
    "Desta forma, a escolha correta dos hiperparametros impacta direto o resultado final. Ou seja, é necessário testar diferentes combinações para encontrar a melhor configuração, e obter a melhor performance depende da habilidade da pessoa que está desenvolvendo o modelo."
   ]
  }
 ]
}
